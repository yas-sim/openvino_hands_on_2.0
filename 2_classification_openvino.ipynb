{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像分類 (classification)プログラム  \n",
    "\n",
    "ここでは簡単な画像分類プログラムを実行していきながらOpenVINO APIの使用方法を学びます。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート  \n",
    "\n",
    "OpenCV (cv2), Numpyなどのライブラリをインポートします。また、Notebook内に画像を表示させるため、PIL (Python Image Library)とIPython.displayもインポートしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import openvino as ov\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの読み込みとコンパイル (最適化)  \n",
    "\n",
    "`resnet50`のモデルを読み込み、`CPU`向けにコンパイルを行います。結果としてコンパイル済みモデルオブジェクトが返されます。  \n",
    "デバイス名を`CPU`, `GPU`, `NPU`などに変えることで、推論実行デバイスを変更することが可能です。  \n",
    "複数のGPUデバイスがシステムに存在する場合、`GPU.0`が内蔵GPU、`GPU.1`以降で外付けGPUを指定可能です。  \n",
    "\n",
    "#### デバイス依存性\n",
    "`compile_model()` APIは\"デバイス非依存\"なOpenVINO IRモデルを、デバイス依存の内部形式にコンパイルを行います。この時にデバイス特化の最適化も行われます。  \n",
    "GPU向けにコンパイルされたコンパイル済みモデルオブジェクトは特定のGPUアーキテクチャや世代に依存するものとなりますので、基本的に他のデバイスに持っていって利用することはできないと考えてください。(`export_model()`, `import_model()`などのAPIを使って他のデバイスで実行できない)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = ov.compile_model('resnet50.xml', device_name='CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論入力データを用意  \n",
    "\n",
    "OpenCVを使用して、画像ファイルを読み込み、モデルの入力シェイプ(サイズ)に合わせて変形します。  \n",
    "また、PILとIPythonの機能を利用してnotebook内に読み込んだ画像を表示させています。\n",
    "\n",
    "#### 入力データのプリプロセス  \n",
    "\n",
    "入力データはモデルの入力サイズや仕様に合わせて前処理が必要です。ここでは下記の前処理を行っています。  \n",
    "|処理|内容|\n",
    "|---|---|\n",
    "|色並びの変換|OpenCVは画像データを\"BGR\"のピクセルオーダーでメモリ中に保持します。多くの推論モデルは\"RGB\"オーダーの画像データを期待しているので、BGR->RGBへの変換を行います|\n",
    "|リサイズ|モデル入力(1,3,224,224)に合わせて、224x224のサイズにリサイズしています|\n",
    "|正規化|多くの推論モデルは入力データ範囲として0.0\\~1.0、または-1.0\\~+1.0のデータを期待しています。また、入力データの中心を0.0に持っていった方が学習がしやすい(収束しやすい)などのメリットがあるため、入力データの平均値を減算したり、偏差を使ったりしてデータの正規化を行う場合があります。**入力データにどのような加工、正規化を行うかは、モデル学習時にどのようなデータ処理を行ったかに依ります**。つまり、推論時に入力するデータは、学習時と同じ前処理が必要ということです。使用するモデルのスペック、仕様を確認してください。<br>ここではピクセル値を255で割って0.0\\~1.0の範囲にしたのち、0.5を減算して数値範囲が-0.5\\~+0.5になるようにしています。|\n",
    "|データ軸の入れ替え|OpenCVの画像データはパックドピクセルデータです(チャネルラスト、`HWC`形式)。今回使用するモデルは`NCHW`のチャネルファーストフォーマットですので、Numpyの`transpose()` APIで軸の順番の入れ替えをします。`HWC`(012) -> `CHW`(201)への変換ですので、(2,0,1)を指定しています。|\n",
    "|軸の追加|ここまでで、データは224x224, `CHW`形式 (3,244,244)への変換が完了していますが、モデルの入力シェイプは`NCHW`の4次元ベクトル(4階 テンソル)です。N==バッチサイズの軸が足りないのでNumpyの`expand_dims()` APIで１つ軸を足して`CHW` -> `NCHW`への変換をしています。ちなみに、`np.reshape(img, (1,3,224,224))`でも同じことが可能です。|\n",
    "\n",
    "以上のデータ操作を行うことで、`img`のシェイプは(1,3,224,224)となり、モデルの入力シェイプと一致させることができました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('beaver.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224,224))\n",
    "display(Image.fromarray(img))\n",
    "img = img.astype(np.float32) / 255.0 - 0.5\n",
    "img = np.transpose(img, (2,0,1))\n",
    "img = np.expand_dims(img, axis=0)    # img = np.reshape(img, (1,3,224,224)) これでもよい (こちらのほうが直感的？)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論実行、結果表示  \n",
    "\n",
    "`infer_new_request()` APIで推論を実行します。  \n",
    "\n",
    "#### 推論結果の後処理  \n",
    "\n",
    "多くの場合、推論モデルの出力はそのままでは役に立ちません。一定の処理を行い、必要な情報に変換するポストプロセス処理が必要となります。このポストプロセス処理は**モデルによっては画像解析などを伴う重い処理となる場合があります**。見落としがちですが、ディープラーニングを活用したプログラムを作成する場合、プリプロセス、ポストプロセスにかかる時間も含めて１推論サイクルとなるので、推論デバイスのTOPS値以外にも注意を払う必要があります。  \n",
    "\n",
    "#### プリプロセス、ポストプロセスの並列実行  \n",
    "\n",
    "今回のチュートリアルでは簡単にしか触れませんが、OpenVINOでは非同期推論APIも提供しています。非同期推論を活用することで推論処理とプリプロセス、ポストプロセスを同時並列に実行させることが可能となり、全体の推論サイクル高速化が可能となります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = compiled_model.infer_new_request(img)    # 推論実行\n",
    "result = result[0].ravel()                        # 最初の出力を取り出し、フラット化 (1,1000) -> (1000,)  すこし速度が落ちるが.flatten()を使用してもよい\n",
    "\n",
    "indices = np.argsort(result)[::-1][:5]            # 出力データを数値の小さい順にソート(argsort())した\"インデックス\"を取得。[::-1]で逆順に並べ替え、先頭の5個を[:5]で取り出す。\n",
    "print(indices)\n",
    "\n",
    "for index in indices:                             # 結果を表示。推定されたクラス番号が表示される\n",
    "    print(index, result[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 結果の表示 (改善)  \n",
    "\n",
    "推論結果がクラス番号だけでは意味が分からないので、クラス名のテキストファイル`synset_words.txt`を読み込み、クラス名を表示できるように改良します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('synset_words.txt') as f:\n",
    "    imagenet_labels = [ line.rstrip().split(maxsplit=1)[1] for line in f.readlines() ]\n",
    "\n",
    "for index in indices:\n",
    "    print(f'class_id {index} : {imagenet_labels[index]}, result[index]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "このチュートリアルではシンプルですが実用的な画像分類モデルを使ったプログラムの実際の流れを見てきました。OpenVINOのAPIとしては非常に単純で難しいところはありませんが、前処理、後処理などモデルを活用するためのにはOpenVINO以外のディープラーニングの基礎知識が必要となります。これは他のフレームワークなどを使用した場合でも基本的に同じことです。  \n",
    "モデルにどのようなデータを入力すればいいか、出てきたデータをどう解釈すればいいかなどは、モデルごとに異なります。使用するモデルの仕様をモデルカードなどの情報を確認してしっかり理解しないとモデルを利用することはできません。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
