{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オブジェクト検出モデルの基本構造を学ぶ  \n",
    "\n",
    "ここではPyTorchのYolo-v5sモデルをOpenVINOで実行する手順について学びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import openvino as ov\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo-v5sモデルをダウンロードする  \n",
    "\n",
    "ダウンロード完了後、`.eval()` APIで推論モードに設定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "pt_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorchのモデルをOpenVINO IRモデルに変換する  \n",
    "\n",
    "PyTorchのモデル変換時にはモデルのシェイプ推論のために`example_input`が必要になる場合があります。推論時に使用するデータと同じシェイプのダミーデータを用意し、それを渡します。データ内容はダミーデータで構いません。  \n",
    "\n",
    "変換が終わったら`yolov5s.xml`という名前でモデルを保存しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.Tensor(size=(1,3,640,640))\n",
    "pt_model(dummy_input)                              # convert_model()での変換時エラーを回避するため、一度モデルを実行しておく。\n",
    "\n",
    "ov_model = ov.convert_model(pt_model, example_input=dummy_input)\n",
    "#ov_model = ov.convert_model(pt_model, example_input=dummy_input, input=[(1,3,640,640)])    # モデルの入力シェイプを固定することも可能\n",
    "\n",
    "ov.save_model(ov_model, 'yolov5s.xml', compress_to_fp16=True)\n",
    "ov_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 変換されたOpenVINO IRモデルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_model = ov.Core().read_model('yolov5s.xml')\n",
    "#ov_model.reshape((1,3,640,640))                # 入力シェイプを固定することも可能\n",
    "print(ov_model)\n",
    "compiled_model = ov.compile_model(ov_model, device_name='GPU.0', config={'CACHE_DIR':'./cache'})\n",
    "compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力画像の読み込みとプリプロセス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('traffic.jpg')\n",
    "print(img.shape)\n",
    "img = cv2.resize(img, (640, 640))\n",
    "reshaped_img = img.copy()\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)   # BGR -> RGB\n",
    "display(Image.fromarray(img))\n",
    "img = np.transpose(img, (2, 0, 1))           # HWC -> CHW  (h,w,c) -> (c,h,w)\n",
    "img = np.expand_dims(img, axis=0)            # CHW -> NCHW (c,h,w) -> (1,c,h,w)\n",
    "img = img.astype(np.float32)\n",
    "img = img / 255\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを実行し、実行時間を計測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "res = compiled_model.infer_new_request(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compiled_model.infer_new_request(img)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ポストプロセス\n",
    "\n",
    "Yoloモデルの推論結果は少し複雑です。出力ノードのテンソルは`[1,25200,85]`のシェイプを持っています。これは、`B, N, 85`のフォーマットで、それぞれ下記のような意味を持ちます。\n",
    "\n",
    "- `B` - バッチサイズ\n",
    "- `N` - 検出したボックス(物体)の数\n",
    "\n",
    "それぞれの検出ボックスのデータフォーマットは [`x`, `y`, `h`, `w`, `box_score`, `class_no_1`, ..., `class_no_80`] のようになっており、それぞれ下記のような意味を持ちます。\n",
    "\n",
    "- (`x`, `y`) - ボックスの中心座標\n",
    "- `h`, `w` - ボックスの幅と高さ\n",
    "- `box_score` - 検出したボックス自身のの信頼度\n",
    "- `class_no_1`, ..., `class_no_80` - 1\\~80までの各オブジェクトクラスID毎の推定確率\n",
    "\n",
    "多くの検出結果は重複（複数の検出ボックスが同一のオブジェクトを検出）しているため、最終的な推論結果を得るためにはNMS (Non-Maximum Suppression)処理を行います。  \n",
    "\n",
    "**これらの出力テンソルフォーマットも使用するモデルによって異なります。** 別のモデルを利用する場合はモデルカードなどでモデルの仕様を確認することが必要です。仮に同じ名前のモデル(Yolo-v5s)であったとしても出力テンソルフォーマットは異なることがあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IOU (Intersection Over Union) ボックスの重なり度を計算\n",
    "def calc_iou(box0, box1):\n",
    "    b0_x0, b0_y0, b0_x1, b0_y1 = box0\n",
    "    b1_x0, b1_y0, b1_x1, b1_y1 = box1\n",
    "    b0_area = (b0_x1 - b0_x0) * (b0_y1 - b0_y0)\n",
    "    b1_area = (b1_x1 - b1_x0) * (b1_y1 - b1_y0)\n",
    "    xx0 = max(b0_x0, b1_x0)\n",
    "    yy0 = max(b0_y0, b1_y0)\n",
    "    xx1 = min(b0_x1, b1_x1)\n",
    "    yy1 = min(b0_y1, b1_y1)\n",
    "    w = max(0, xx1 - xx0)\n",
    "    h = max(0, yy1 - yy0)\n",
    "    intersect = w * h\n",
    "    union = (b0_area + b1_area - intersect)\n",
    "    iou = intersect / union\n",
    "    return iou\n",
    "\n",
    "# ボックス同士が大きく重なっている場合、信頼度の高い方だけを残す処理\n",
    "# Non-Maximum suppression\n",
    "# 私がいい加減に実装したNMSアルゴリズムですので、もっと最適化された実装があります。\n",
    "def nms(predicts, iou_threshold=0.5):\n",
    "    # predicts = x0, y0, x1, y1, score, *classes[80]\n",
    "    predicts = predicts[np.argsort(predicts[:,4])]   # ボックス信頼度でソート\n",
    "    res = []\n",
    "    while(len(predicts)>0):\n",
    "        res.append(predicts[0])\n",
    "        box0 = predicts[0][:4]\n",
    "        remove_indices = [0]\n",
    "        # ボックスの重なり度を計算し、一定以上重なっている場合は信頼度の低い方を取り除く (後で取り除くためにインデックスを記録しておく)\n",
    "        for idx in range(1, len(predicts)):\n",
    "            box1 = predicts[idx][:4]\n",
    "            iou = calc_iou(box0, box1)\n",
    "            if iou > iou_threshold:\n",
    "                remove_indices.append(idx)\n",
    "        for idx in remove_indices[::-1]:  # 記録しておいた削除予定ボックスを後ろから削除していく (前から削除するとインデックス番号がずれるため)\n",
    "            predicts = np.delete(predicts, idx, axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表示用のクラスラベル  \n",
    "\n",
    "今回のYolo v5sモデルはMS COCOデータセットで学習されているので、coco_class_labelを使用します。  \n",
    "使用するモデルによってクラス名の定義は異なりますので、他のモデルを使用する場合はモデルのスペックをよく確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_class_label = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "                    'fire hydrant', 'street_sign', 'stop sign','parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', \n",
    "                    'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', \n",
    "                    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "                    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
    "                    'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n",
    "                    'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet',\n",
    "                    'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "                    'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush',\n",
    "                    'hair brush']\n",
    "\n",
    "pascal_voc_class_label = ['Person', 'Car', 'Bicycle', 'Bus', 'Motorbike', 'Train', 'Aeroplane', 'Chair', 'Bottle', 'Dining Table', 'Potted Plant', \n",
    "                          'TV/Monitor', 'Sofa', 'Bird', 'Cat', 'Cow', 'Dog', 'Horse', 'Sheep' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 検出結果のBBox (bounding box)とラベルを画像上に描画するための関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img, predicts, score_limit=0.7):\n",
    "    for bbox in predicts:\n",
    "        x0, y0, x1, y1 = bbox[:4].astype(np.int32)\n",
    "        box_score = bbox[4]\n",
    "        if box_score > score_limit:\n",
    "            # Bboxの描画\n",
    "            cv2.rectangle(img, (x0, y0), (x1, y1), (0, 255, 0), thickness=1)\n",
    "            # クラスラベルの描画\n",
    "            class_id = np.argmax(bbox[5:])\n",
    "            text = coco_class_label[class_id]\n",
    "            (w, h), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, fontScale=1, thickness=1)\n",
    "            cv2.rectangle(img, (x0, y0), (x0 + w, y0 - h - baseline), color=(0,255,0), thickness=-1)\n",
    "            cv2.putText(img, text, (x0, y0 - baseline), cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(0,0,0), thickness=1)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(img)\n",
    "    display(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論結果の事前加工  \n",
    "\n",
    "ボックスの座標が`[center_x, center_y, height, width]`では扱いにくいので、`[x0, y0, x1, y1]`になるようにデータを操作します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = res[0][0].copy()    # (25200, 85)\n",
    "# predicts = x, y, h, w, score, *classes[80]\n",
    "\n",
    "x = predicts[:, 0].copy()\n",
    "y = predicts[:, 1].copy()\n",
    "h = predicts[:, 2].copy()\n",
    "w = predicts[:, 3].copy()\n",
    "predicts[:, 0] = x - h/2\n",
    "predicts[:, 1] = y - w/2\n",
    "predicts[:, 2] = x + h/2\n",
    "predicts[:, 3] = y + w/2\n",
    "# predicts = x0, y0, x1, y1, score, *classes[80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論結果の表示 1 - そのまま  \n",
    "\n",
    "NMSを適用せず、検出したすべてのBboxを描画してみます。  \n",
    "一つのオブジェクトに複数のBboxが重複して割り当てられているのがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of bbox =', predicts.shape[0])\n",
    "score_limit = 0.65\n",
    "\n",
    "out_img = reshaped_img.copy()\n",
    "draw_bbox(out_img, predicts, score_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bbox信頼度0.65未満のデータを切り捨ててみる\n",
    "\n",
    "25,200個のBboxに対して素直にNMSを適用すると計算コストが大きくなりすぎます。  \n",
    "先に信頼度の低いBboxを除外することで計算負荷を下げます。\n",
    "\n",
    "まだ重なっているBboxがたくさんあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# screen out low score predicted items\n",
    "score_limit = 0.65\n",
    "predicts = np.array([predict for predict in predicts if predict[4]>score_limit])\n",
    "print('Number of Bbox =', predicts.shape[0])\n",
    "\n",
    "out_img = reshaped_img.copy()\n",
    "draw_bbox(out_img, predicts, score_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMSを適用して、最終結果を描画する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMS : Non Maximum Suppression\n",
    "nms_result = nms(predicts, 0.8)\n",
    "print('Number of bbox =', len(nms_result))\n",
    "\n",
    "out_img = reshaped_img.copy()\n",
    "draw_bbox(out_img, nms_result, score_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ  \n",
    "\n",
    "ここではYolo v5sモデルを使用した物体検出プログラムの基礎を学習しました。物体検出モデルは出力テンソルのフォーマットもモデルごとに微妙に異ります。また、モデルによってはbbox (bounding box)を直接検出するのではなく、「物体の存在確率」をヒートマップで出力するようなタイプのモデルもあります。物体検出モデルに限った話ではありませんが、モデルに合わせたポストプロセスを実装する必要があることを覚えておいてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
