{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの最適化  \n",
    "\n",
    "## トレーニング後量子化 - Post Training Quantization : PTQ  \n",
    "\n",
    "ここでは、先ほどの学習済みResnet50モデルをINT8量子化することでモデルサイズを小さくし、推論パフォーマンスを向上させる方法について学びます。  \n",
    "\n",
    "#### NNCF - Neural Network Compression Framework\n",
    "モデルの量子化にはOpenVINOの関連ツール[NNCF](https://github.com/openvinotoolkit/nncf)を使用します。  \n",
    "NNCFはQATとPTQの2つのモードでモデルの最適化を行うことができるツールです。**ここでは学習済みモデルの量子化を行うのでPTQモードを使用します**。    \n",
    "NNCFはOpenVINOパッケージには含まれていません。別途インストールを行う必要があります。 \n",
    "```sh\n",
    "pip install nncf\n",
    "```\n",
    "使用するフレームワークも一緒にインストールするにはオプションを追加します。\n",
    "```sh\n",
    "pip install nncf[torch,tensorflow,onnx]\n",
    "```\n",
    "\n",
    "|モード|説明|\n",
    "|---|---|\n",
    "|[QAT : Quantize Aware Training](https://docs.openvino.ai/2024/openvino-workflow/model-optimization-guide/compressing-models-during-training.html)|モデルの学習中に量子化を行います。そのため、推論精度を犠牲にすることなくモデルの量子化を行うことが可能です。|\n",
    "|[PTQ : Post Training Quantization](https://docs.openvino.ai/2024/openvino-workflow/model-optimization-guide/quantizing-models-post-training.html)|学習が終わったモデルデータを量子化します。ある程度の推論精度劣化を伴います。<br>アクティベーションレイヤーの統計データを元に量子化を行うために推論入力データが必要となります。通常は学習時に使用したデータセットのバリデーションデータなどを流用します。<br>また、[推論精度の劣化程度をコントロールすることができるモード](https://docs.openvino.ai/2024/openvino-workflow/model-optimization-guide/quantizing-models-post-training/quantizing-with-accuracy-control.html)もあります。|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## キャリブレーション用データセットのダウンロード  \n",
    "\n",
    "'tiny-imagenet-200'をダウンロードし、展開します。(242MB)  \n",
    "このデータセットに含まれる画像は64x64 (64,64,3)ですが、そのまま使用します。  \n",
    "\n",
    "PTQを行うには入力データ(今回は画像分類モデル、Resnet50をPTQするので画像データ)が必要になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "if not os.path.exists('tiny-imagenet-200.zip'):\n",
    "    urllib.request.urlretrieve('http://cs231n.stanford.edu/tiny-imagenet-200.zip', 'tiny-imagenet-200.zip')\n",
    "if not os.path.exists('tiny-imagenet-200'):\n",
    "    shutil.unpack_archive('tiny-imagenet-200.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import openvino as ov\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import nncf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorchのResnet50モデルを読み込む  \n",
    "\n",
    "PyTorchの学習済みResnet50モデルを読み込みます。  \n",
    "また、後のパフォーマンス比較で使うため、FP16のOpenVINO IRモデルに変換し、`resnet50_fp16.xml`という名前で保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "resnet50.eval()\n",
    "\n",
    "ov_model = ov.convert_model(resnet50, example_input=torch.rand(1,3,224,224).cpu())\n",
    "ov.save_model(ov_model, 'resnet50_fp16.xml', compress_to_fp16=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNCFでPTQ(トレーニング後最適化)を実施するためのデータセットを準備する  \n",
    "\n",
    "PyTorchなどで用意されているデータセットをそのまま利用できる場合は、それを利用したほうが簡単な場合もあります。  \n",
    "[Post-Training Quantization of MobileNet v2 PyTorch Model](https://github.com/openvinotoolkit/nncf/tree/develop/examples/post_training_quantization/torch/mobilenet_v2)\n",
    "\n",
    "ここでは、自分で用意したキャリブレーションデータを利用する場合を想定して、キャリブレーションデータセットを用意する簡易なコードを用意しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "resnet50.eval()\n",
    "\n",
    "# モデルの入力に合わせて読み込んだ画像データをプリプロセスする\n",
    "def preprocess(img, scale_val=255.0, mean_val=(0.485, 0.456, 0.406), std_val=(0.229, 0.224, 0.225)):\n",
    "    img = cv2.resize(img, (224,224))                   # 224x224にリサイズ\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)         # BGR -> RGB\n",
    "    img = (img.astype(np.float32) / 255.0) - 0.5       # 正規化 (0-255) -> (-0.5 - +0.5) \n",
    "    img = np.transpose(img, (2,0,1))                   # 軸の入れ替え HWC -> CHW\n",
    "    return img                                         # この時点で (3,224,224)になっている\n",
    "\n",
    "# 用意したデータローダーから与えられたデータアイテムからモデル入力データだけを抜き出すユーザー関数\n",
    "# データアイテムは (img, label_id)が与えられることを想定。label_idは捨て、imgだけを抜き出す\n",
    "def transform_fn(data_item):\n",
    "    image, _ = data_item\n",
    "    return image\n",
    "\n",
    "# データセットオブジェクトを作成\n",
    "# (image, label_id)のリスト\n",
    "image_files = glob.glob('./tiny-imagenet-200/test/images/**/*.JPEG', recursive=True)     # データセット内にあるJPEGファイルパスのリストを取得\n",
    "print(f'{len(image_files)} images found.')\n",
    "dataset = [ (preprocess(cv2.imread(file_name)), 0) for file_name in image_files ]        # (image_data, label_id)で構成されるリストを作成する。label_idはダミー(0)固定\n",
    "\n",
    "# データセットをデータローダーにセットし、キャリブレーションデータセットとする\n",
    "val_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
    "calibration_dataset = nncf.Dataset(val_loader, transform_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTQ量子化を実行する  \n",
    "\n",
    "量子化が終了後、量子化済みモデルをファイルに保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorchモデルの量子化実行\n",
    "quantized_model = nncf.quantize(resnet50, calibration_dataset)\n",
    "\n",
    "# 量子化済みモデルをOpenVINO IRモデルに変換し、保存\n",
    "ov_model_int8 = ov.convert_model(quantized_model, example_input=torch.rand(1,3,224,224).cpu())\n",
    "ov.save_model(ov_model_int8, 'resnet50_int8.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量子化前のモデルと、量子化済みモデルのサイズを確認する  \n",
    "\n",
    "`resnet50_fp16.bin`と`resnet50_int8.bin`のファイルサイズを確認してください。  \n",
    "量子化したint8モデルのほうが小さくなっているはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'nt':\n",
    "    !dir *.bin\n",
    "else:\n",
    "    !ls -l *.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量子化したモデルを実際に試してみる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量子化前(fp16)のモデルと量子化後(int8)のモデルをロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'CPU'\n",
    "config = { 'CACHE_DIR' : './cache' }\n",
    "\n",
    "compiled_model_fp16 = ov.compile_model('resnet50_fp16.xml', device, config=config)\n",
    "compiled_model_int8 = ov.compile_model('resnet50_int8.xml', device, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力画像の読み込みとプリプロセス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "img = cv2.imread('beaver.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (224,224))\n",
    "display(Image.fromarray(img))\n",
    "img = img.astype(np.float32) / 255.0 - 0.5\n",
    "img = np.transpose(img, (2,0,1))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量子化前(fp16)モデル  \n",
    "\n",
    "モデルの推論結果と実行時間(wall time)を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit compiled_model_fp16.infer_new_request(img)\n",
    "\n",
    "with open('synset_words.txt') as f:\n",
    "    imagenet_labels = [ line.rstrip().split(maxsplit=1)[1] for line in f.readlines() ]\n",
    "\n",
    "result = compiled_model_fp16.infer_new_request(img)\n",
    "res = result[0].ravel()\n",
    "indices = np.argsort(res)[::-1]\n",
    "\n",
    "for index in indices[:5]:\n",
    "    print(index, imagenet_labels[index], res[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量子化前(int8)モデル  \n",
    "\n",
    "モデルの推論結果と実行時間(wall time)を確認してください。fp16モデルとパフォーマンスを比較してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit compiled_model_int8.infer_new_request(img)\n",
    "\n",
    "with open('synset_words.txt') as f:\n",
    "    imagenet_labels = [ line.rstrip().split(maxsplit=1)[1] for line in f.readlines() ]\n",
    "\n",
    "result = compiled_model_int8.infer_new_request(img)\n",
    "res = result[0].ravel()\n",
    "indices = np.argsort(res)[::-1]\n",
    "\n",
    "for index in indices[:5]:\n",
    "    print(index, imagenet_labels[index], res[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ  \n",
    "\n",
    "ここではNNCFを使用してモデルの学習後量子化をする方法について学びました。  \n",
    "NNCFは他にも学習時量子化や、プルーニングなど多くの機能があります。  \n",
    "[OpenVINO Notebooks](https://openvinotoolkit.github.io/openvino_notebooks/)にも、モデル最適化に関する多くのチュートリアルがありますので参考にしてください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
