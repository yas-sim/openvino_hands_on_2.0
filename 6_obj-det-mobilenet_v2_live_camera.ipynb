{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オブジェクト検出のライブデモプログラムの作り方を理解する  \n",
    "\n",
    "ここでは、jupyter notebookを使用したライブデモの作り方を学びます。  \n",
    "ムービーファイルやWebCam (USBカメラ)から画像を読み込み、リアルタイムに推論結果を表示するデモの構成を見ていきましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート  \n",
    "\n",
    "Note: Windows上でOpenCVでWebCamをオープンすると30秒以上待たされることがあります。これを回避するため、`OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS`環境変数に`0`を設定しています。これは`import cv2`よりも先に記述する必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "os.environ[\"OPENCV_VIDEOIO_MSMF_ENABLE_HW_TRANSFORMS\"] = \"0\"   # Expedite WebCam initialization in OpenCV (on Windows)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import openvino as ov\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表示用のクラスラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_class_label = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "                    'fire hydrant', 'street_sign', 'stop sign','parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', \n",
    "                    'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', \n",
    "                    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "                    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
    "                    'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n",
    "                    'cake', 'chair', 'couch', 'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet',\n",
    "                    'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "                    'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush',\n",
    "                    'hair brush']\n",
    "\n",
    "coco_class_label = [ '_background_' ] + coco_class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlowの物体検出モデル (ssd-mobilenet-v2)を読み込み、OpenVINO IR形式に変換し、ファイルに保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub\n",
    "\n",
    "if not os.path.exists('ssd-mobilenet-v2.xml'):\n",
    "    detector = tensorflow_hub.load(\"https://www.kaggle.com/models/tensorflow/ssd-mobilenet-v2/frameworks/TensorFlow2/variations/ssd-mobilenet-v2/versions/1\")\n",
    "    ov_model = ov.convert_model(detector)\n",
    "    ov.save_model(ov_model, 'ssd-mobilenet-v2.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存したOpenVINO IRモデルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ov_core = ov.Core()\n",
    "ov_model = ov_core.read_model('ssd-mobilenet-v2.xml')\n",
    "ov_model.reshape((1,300,300,3))\n",
    "compiled_model = ov.compile_model(ov_model, 'CPU', config={'CACHE_DIR':'./cache'})\n",
    "#compiled_model = ov.compile_model('mobilenet_v2.xml', 'GPU.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ビデオストリームをオープンする  \n",
    "\n",
    "`cv2.VideoCapture()`の引数に`0`を渡すと0番目のUSBカメラを、ファイル名を指定するとムービーファイルをオープンします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_source = 0                          # 0, \"sample.mp4\", etc  (0 means Webcam #0)\n",
    "#video_source = \"people-detection.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "if cap.isOpened():\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH , 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "else:\n",
    "    print(f'Failed to open {video_source}.') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表示部分 (画像読み込み＋推論実行＋後処理＋結果描画）\n",
    "\n",
    "`ssd-mobilenet-v2`はYolo系とは異なる、SSD (Single Shot multibox Detector)系のアーキテクチャのモデルです。SSDモデルのバックボーン部にmobilenetアーキテクチャのモデルを利用しているモデルです。  \n",
    "Yolo系とは出力テンソルのフォーマットが異なり、通常はNMS済みのBboxデータだけが出力されます。つまり、モデル側でNMS処理を行ってくれているので、ユーザープログラム側ではNMSを実行する必要はありません。Bbox信頼度に基づき、推論結果を画像上に描画すればOKです。  \n",
    "\n",
    "このセルでは一定時間ループ処理を行ったのち終了します。ループ内ではユーザーからのキーボードやマウスからの入力を受け取る部分がなく、途中で中断するにはJupyter notebookのカーネルをinterruptするしかありません。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描画した画像を表示する準備\n",
    "notebook_display = IPython.display.display(display_id=1)\n",
    "\n",
    "stime = time.time()\n",
    "\n",
    "while time.time() - stime < 50:                               # 指定の秒数だけ実行する (50秒)\n",
    "\n",
    "    # ビデオストリームから１フレーム読み込む\n",
    "    ret, img = cap.read()                                     \n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    # プリプロセス\n",
    "    img = cv2.resize(img, (300, 300))\n",
    "    tensor = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)             # BGR -> RGB\n",
    "    tensor = np.expand_dims(tensor, axis=0).astype(np.uint8)  # HWC -> NHWC (h,w,c) -> (1,h,w,c)\n",
    "    #tensor = (tensor.astype(np.float32)/255.0-0.5)/0.2\n",
    "\n",
    "    # 推論実行\n",
    "    res = compiled_model.infer_new_request(tensor)\n",
    "\n",
    "    img_w, img_h, _ = img.shape                               # 入力画像のサイズを取得\n",
    "\n",
    "    # ポストプロセス ＋ 結果の画面描画\n",
    "    num_detections = int(res['num_detections'][0])            # 検出ボックス数\n",
    "    for (rel_y0,rel_x0,rel_y1,rel_x1), class_id, score in zip(res['detection_boxes'][0], res['detection_classes'][0], res['detection_scores'][0]):  # Bboxごとに処理\n",
    "        if score > 0.65:                 # Bboxの信頼度が0.65 (65%)以上ならBboxを描画。それ以下なら無視。\n",
    "            x0 = int(img_w * rel_x0)\n",
    "            y0 = int(img_h * rel_y0)\n",
    "            x1 = int(img_w * rel_x1)\n",
    "            y1 = int(img_h * rel_y1)\n",
    "            # Bboxの描画\n",
    "            cv2.rectangle(img, (x0, y0), (x1, y1), (0,255,0), 1)\n",
    "            # クラスラベルの描画\n",
    "            text = coco_class_label[int(class_id)]\n",
    "            (w, h), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, fontScale=1, thickness=1)\n",
    "            cv2.rectangle(img, (x0, y0), (x0 + w, y0 - h - baseline), color=(0,255,0), thickness=-1)\n",
    "            cv2.putText(img, text, (x0, y0 - baseline), cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(0,0,0), thickness=1)\n",
    "\n",
    "    # 画像を表示\n",
    "    _, jpg_img = cv2.imencode('.jpg', img, [cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "    notebook_display.update(IPython.display.Image(data=BytesIO(jpg_img).getvalue()))\n",
    "\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ビデオストリームを閉じる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ  \n",
    "\n",
    "ここではJupyter notebookを利用してリアルタイムデモを作るしくみの基礎を学びました。Jupyter bookにはほかにも画像を表示するための仕組みなどがありますので調べてみてください。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## おまけ  \n",
    "\n",
    "普通にOpenCVの`cv2.imshow()`を使って結果を表示することも可能です。その場合、Jupyter notebookとは別のWindowが開き、そこに結果が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "video_source = 0                          # 0, \"sample.mp4\", etc  (0 means Webcam #0)\n",
    "#video_source = \"people-detection.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "if cap.isOpened():\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH , 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "else:\n",
    "    print(f'Failed to open {video_source}.') \n",
    "\n",
    "stime = time.time()\n",
    "\n",
    "key = -1\n",
    "while key!=27 and key!=ord('q'):                               # ESCか'q'が押されるまで実行\n",
    "\n",
    "    # ビデオストリームから１フレーム読み込む\n",
    "    ret, img = cap.read()                                     \n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    # プリプロセス\n",
    "    img = cv2.resize(img, (300, 300))\n",
    "    tensor = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)             # BGR -> RGB\n",
    "    tensor = np.expand_dims(tensor, axis=0).astype(np.uint8)  # HWC -> NHWC (h,w,c) -> (1,h,w,c)\n",
    "    #tensor = (tensor.astype(np.float32)/255.0-0.5)/0.2\n",
    "\n",
    "    # 推論実行\n",
    "    res = compiled_model.infer_new_request(tensor)\n",
    "\n",
    "    img_w, img_h, _ = img.shape                               # 入力画像のサイズを取得\n",
    "\n",
    "    # ポストプロセス ＋ 結果の画面描画\n",
    "    num_detections = int(res['num_detections'][0])            # 検出ボックス数\n",
    "    for (rel_y0,rel_x0,rel_y1,rel_x1), class_id, score in zip(res['detection_boxes'][0], res['detection_classes'][0], res['detection_scores'][0]):  # Bboxごとに処理\n",
    "        if score > 0.65:                 # Bboxの信頼度が0.65 (65%)以上ならBboxを描画。それ以下なら無視。\n",
    "            x0 = int(img_w * rel_x0)\n",
    "            y0 = int(img_h * rel_y0)\n",
    "            x1 = int(img_w * rel_x1)\n",
    "            y1 = int(img_h * rel_y1)\n",
    "            # Bboxの描画\n",
    "            cv2.rectangle(img, (x0, y0), (x1, y1), (0,255,0), 1)\n",
    "            # クラスラベルの描画\n",
    "            text = coco_class_label[int(class_id)]\n",
    "            (w, h), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_PLAIN, fontScale=1, thickness=1)\n",
    "            cv2.rectangle(img, (x0, y0), (x0 + w, y0 - h - baseline), color=(0,255,0), thickness=-1)\n",
    "            cv2.putText(img, text, (x0, y0 - baseline), cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(0,0,0), thickness=1)\n",
    "\n",
    "    # 画像を表示\n",
    "    cv2.imshow('Result', img)          # OpenCVを使って結果画像を表示 (別ウインドウに表示される)\n",
    "    key = cv2.waitKey(1)               # キー入力を読み取る (OpenCVでは`imshow()`を読んだだけでは画像は表示されません。`waitKey()`が呼ばれたタイミングでウインドウへの実際の描画がなされるので、`waitKey()`を省略することはできません。\n",
    "\n",
    "cap.release()                   # ビデオストリームを閉じる\n",
    "cv2.destroyAllWindows()         # すべてのOpenCVウインドウを閉じる\n",
    "\n",
    "print('Finished.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
